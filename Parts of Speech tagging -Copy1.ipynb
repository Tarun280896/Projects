{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from nltk import pos_tag,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "category_list = ['comp.sys.mac.hardware','rec.autos','misc.forsale','sci.space','talk.politics.guns']\n",
    "new_groups = fetch_20newsgroups(categories=category_list,remove=('headers','footers','quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n740 Turbo in UK was good for 124mph. Useful for blowing away VW Beetles, though I\\nbelieve the Beetle corners better. \\n\\nI can say without any doubt that I have never been blown away by any Volvo, ever.\\nI've been blocked into a few car parks though by shit-head Volvo owners who 'only thought they'd be a few minutes'. This does not happen with the owners of any other makes of car.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = new_groups.data\n",
    "doc_df= pd.DataFrame(doc,columns={'Document':0})\n",
    "doc_df.loc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n740 Turbo in UK was good for 124mph. Useful ...</td>\n",
       "      <td>turbo in uk was good for    mph  useful f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am looking for a working docking deck (deck ...</td>\n",
       "      <td>i am looking for a working docking deck  deck ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n &gt;In article &lt;1993Apr19.020359.26996@sq.sq.c...</td>\n",
       "      <td>in article      apr                sq sq co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A few posts back, somebody mentioned that the ...</td>\n",
       "      <td>a few posts back  somebody mentioned that the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\nIt still applies, except the astro...</td>\n",
       "      <td>it still applies  except the astronomy t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document  \\\n",
       "0  \\n740 Turbo in UK was good for 124mph. Useful ...   \n",
       "1  I am looking for a working docking deck (deck ...   \n",
       "2  \\n >In article <1993Apr19.020359.26996@sq.sq.c...   \n",
       "3  A few posts back, somebody mentioned that the ...   \n",
       "4  \\n\\n\\n\\n\\n\\nIt still applies, except the astro...   \n",
       "\n",
       "                                          clean_text  \n",
       "0       turbo in uk was good for    mph  useful f...  \n",
       "1  i am looking for a working docking deck  deck ...  \n",
       "2     in article      apr                sq sq co...  \n",
       "3  a few posts back  somebody mentioned that the ...  \n",
       "4        it still applies  except the astronomy t...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_df['clean_text']=doc_df['Document'].str.lower().str.replace(\"[^a-z]\",\" \")\n",
    "doc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    turbo uk good mph useful blowing away vw beetl...\n",
       "1    looking working docking deck deck goes back ca...\n",
       "2    article apr sq sq com msb sq sq com mark brade...\n",
       "3    posts back somebody mentioned duo might crash ...\n",
       "4    still applies except astronomy days long basel...\n",
       "Name: Final, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "def sw(text):\n",
    "    text = [word for word in text.split() if word not in stop] # spliting the words with space\n",
    "    return \" \".join(text) #\n",
    "\n",
    "doc_df['Final'] = doc_df['clean_text'].apply(sw)\n",
    "doc_df['Final'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfun(text):\n",
    "    a = word_tokenize(text)\n",
    "    nltk.pos_tag(a)\n",
    "    nouns = []\n",
    "    is_noun = lambda x:x[:2] == 'NN'\n",
    "    noun = [word for (word,x) in pos_tag(a) if is_noun(x)]\n",
    "    nouns.extend(noun)\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['turbo',\n",
       " 'mph',\n",
       " 'beetles',\n",
       " 'corners',\n",
       " 'doubt',\n",
       " 'car',\n",
       " 'parks',\n",
       " 'head',\n",
       " 'volvo',\n",
       " 'owners',\n",
       " 'minutes',\n",
       " 'owners',\n",
       " 'car',\n",
       " 'deck',\n",
       " 'deck',\n",
       " 'camera',\n",
       " 'jvc',\n",
       " 'gx',\n",
       " 'tube',\n",
       " 'video',\n",
       " 'camera',\n",
       " 'format',\n",
       " 'please',\n",
       " 'message',\n",
       " 'anything',\n",
       " 'decks',\n",
       " 'video',\n",
       " 'equipment',\n",
       " 'sale',\n",
       " 'consumer',\n",
       " 'thank',\n",
       " 'freedom',\n",
       " 'van',\n",
       " 'freedom',\n",
       " 'bbs',\n",
       " 'article',\n",
       " 'apr',\n",
       " 'sq',\n",
       " 'sq',\n",
       " 'com',\n",
       " 'msb',\n",
       " 'sq',\n",
       " 'sq',\n",
       " 'com',\n",
       " 'mark',\n",
       " 'brader',\n",
       " 'mb',\n",
       " 'mb',\n",
       " 'figure',\n",
       " 'anything',\n",
       " 'jg',\n",
       " 'sorry',\n",
       " 'perijoves',\n",
       " 'language',\n",
       " 'periapsis',\n",
       " 'apoapsis',\n",
       " 'posts',\n",
       " 'somebody',\n",
       " 'duo',\n",
       " 'kind',\n",
       " 'non',\n",
       " 'self',\n",
       " 'duo',\n",
       " 'crashes',\n",
       " 'software',\n",
       " 'kind',\n",
       " 'ram',\n",
       " 'problem',\n",
       " 'battery',\n",
       " 'connection',\n",
       " 'thanks',\n",
       " 'advance',\n",
       " 'days',\n",
       " 'radio',\n",
       " 'astronomy',\n",
       " 'gps',\n",
       " 'data',\n",
       " 'observatory',\n",
       " 'others',\n",
       " 'source',\n",
       " 'data',\n",
       " 'studies',\n",
       " 'dynamics',\n",
       " 'rotation',\n",
       " 'purturbations',\n",
       " 'time',\n",
       " 'second',\n",
       " 'year',\n",
       " 'science',\n",
       " 'vlbi',\n",
       " 'track',\n",
       " 'gallileo',\n",
       " 'earth',\n",
       " 'fuel',\n",
       " 'afford',\n",
       " 'observe',\n",
       " 'ida',\n",
       " 'john',\n",
       " 'spencer',\n",
       " 'spencer',\n",
       " 'eclipses',\n",
       " 'rings',\n",
       " 'word',\n",
       " 'information',\n",
       " 'events',\n",
       " 'couple',\n",
       " 'messages',\n",
       " 'jpl',\n",
       " 'observations',\n",
       " 'properties',\n",
       " 'iapetus',\n",
       " 'money',\n",
       " 'john',\n",
       " 'spencer',\n",
       " 'iapetus',\n",
       " 'shadows',\n",
       " 'rings',\n",
       " 'timing',\n",
       " 'ingress',\n",
       " 'egress',\n",
       " 'c',\n",
       " 'saturn',\n",
       " 'ingress',\n",
       " 'egress',\n",
       " 'egress',\n",
       " 'egress',\n",
       " 'july',\n",
       " 'egress',\n",
       " 'grazing',\n",
       " 'egress',\n",
       " 'times',\n",
       " 'minutes',\n",
       " 'ephemeris',\n",
       " 'observations',\n",
       " 'refining',\n",
       " 'iapetus',\n",
       " 'orbit',\n",
       " 'size',\n",
       " 'rings',\n",
       " 'km',\n",
       " 'anything',\n",
       " 'rings',\n",
       " 'observations',\n",
       " 'astrophysics',\n",
       " 'l',\n",
       " 'details',\n",
       " 'thanks',\n",
       " 'arizona',\n",
       " 'university',\n",
       " 'events',\n",
       " 'attention',\n",
       " 'observations',\n",
       " 'thing',\n",
       " 'july',\n",
       " 'disappearance',\n",
       " 'shadow',\n",
       " 'planet',\n",
       " 'measure',\n",
       " 'inertia',\n",
       " 'event',\n",
       " 'renders',\n",
       " 'russia',\n",
       " 'alto',\n",
       " 'saturn',\n",
       " 'airmasses',\n",
       " 'anyone',\n",
       " 'russia',\n",
       " 'telescope',\n",
       " 'instrumentation',\n",
       " 'something',\n",
       " 'grant',\n",
       " 'data',\n",
       " 'jay',\n",
       " 'please',\n",
       " 'anyone',\n",
       " 'observe',\n",
       " 'iapetus',\n",
       " 'planet',\n",
       " 'disappearance',\n",
       " 'impression',\n",
       " 'observation',\n",
       " 'iapetus',\n",
       " 'faint',\n",
       " 'fainter',\n",
       " 'eclipse',\n",
       " 'telescope',\n",
       " 'ir',\n",
       " 'telescope',\n",
       " 'instrumentation',\n",
       " 'combination',\n",
       " 'longitudes',\n",
       " 'observation',\n",
       " 'need',\n",
       " 'possibility',\n",
       " 'telescope',\n",
       " 'india',\n",
       " 'jay',\n",
       " 'kind',\n",
       " 'comparison',\n",
       " 'processor',\n",
       " 'computer',\n",
       " 'computer',\n",
       " 'comparing',\n",
       " 'processor',\n",
       " 'speed',\n",
       " 'increase',\n",
       " 'clock',\n",
       " 'speed',\n",
       " 'increase',\n",
       " 'speed',\n",
       " 'things',\n",
       " 'conditions',\n",
       " 'program',\n",
       " 'lot',\n",
       " 'functions',\n",
       " 'functions',\n",
       " 'fpu',\n",
       " 'people',\n",
       " 'computers',\n",
       " 'processor',\n",
       " 'name',\n",
       " 'alway',\n",
       " 'things',\n",
       " 'speed',\n",
       " 'restrict',\n",
       " 'arguements',\n",
       " 'example',\n",
       " 'pure',\n",
       " 'issues',\n",
       " 'processor',\n",
       " 'work',\n",
       " 'design',\n",
       " 'get',\n",
       " 'discussions',\n",
       " 'yang',\n",
       " 'article',\n",
       " 'apr',\n",
       " 'galileo',\n",
       " 'cc',\n",
       " 'rochester',\n",
       " 'edu',\n",
       " 'pin',\n",
       " 'simms',\n",
       " 'configs',\n",
       " 'case',\n",
       " 'memory',\n",
       " 'board',\n",
       " 'sockets',\n",
       " 'mb',\n",
       " 'memory',\n",
       " 'interpretations',\n",
       " 'militia',\n",
       " 'security',\n",
       " 'state',\n",
       " 'people',\n",
       " 'arms',\n",
       " 'people',\n",
       " 'members',\n",
       " 'militia',\n",
       " 'bear',\n",
       " 'arms',\n",
       " 'businessmen',\n",
       " 'ability',\n",
       " 'nation',\n",
       " 'marketplace',\n",
       " 'people',\n",
       " 'schools',\n",
       " 'businessmen',\n",
       " 'attend',\n",
       " 'schools',\n",
       " 'texas',\n",
       " 'period',\n",
       " 'numbers',\n",
       " 'suicides',\n",
       " 'accidents',\n",
       " 'number',\n",
       " 'department',\n",
       " 'safety',\n",
       " 'murders',\n",
       " 'car',\n",
       " 'fatalities',\n",
       " 'gun',\n",
       " 'laws',\n",
       " 'aside',\n",
       " 'states',\n",
       " 'state',\n",
       " 'virginia',\n",
       " 'law',\n",
       " 'inflicts',\n",
       " 'rights',\n",
       " 'life',\n",
       " 'liberty',\n",
       " 'pursuit',\n",
       " 'happiness',\n",
       " 'place',\n",
       " 'weapons',\n",
       " 'please',\n",
       " 'anything',\n",
       " 'people',\n",
       " 'sables',\n",
       " 'cars',\n",
       " 'site',\n",
       " 'year',\n",
       " 'company',\n",
       " 'year',\n",
       " 'employees',\n",
       " 'folks',\n",
       " 'buy',\n",
       " 'complaints',\n",
       " 'cars',\n",
       " 'nice',\n",
       " 'cache',\n",
       " 'card',\n",
       " 'iisi',\n",
       " 'max',\n",
       " 'kb',\n",
       " 'socket',\n",
       " 'slot',\n",
       " 'adapter',\n",
       " 'connector',\n",
       " 'card',\n",
       " 'need',\n",
       " 'advice',\n",
       " 'card',\n",
       " 'performance',\n",
       " 'increase',\n",
       " 'performance',\n",
       " 'increase',\n",
       " 'kb',\n",
       " 'cache',\n",
       " 'price',\n",
       " 'difference',\n",
       " 'price',\n",
       " 'card',\n",
       " 'ethernet',\n",
       " 'card',\n",
       " 'think',\n",
       " 'fpu',\n",
       " 'card',\n",
       " 'fpu',\n",
       " 'socket',\n",
       " 'pay',\n",
       " 'fpu',\n",
       " 'hi',\n",
       " 'canada',\n",
       " 'gun',\n",
       " 'enters',\n",
       " 'park',\n",
       " 'metal',\n",
       " 'tag',\n",
       " 'result',\n",
       " 'use',\n",
       " 'gun',\n",
       " 'bears',\n",
       " 'parks',\n",
       " 'dangers',\n",
       " 'annoyances',\n",
       " 'country',\n",
       " 'precautions',\n",
       " 'policy',\n",
       " 'users',\n",
       " 'parks',\n",
       " 'nature',\n",
       " 'part',\n",
       " 'nature',\n",
       " 'deal',\n",
       " 'nature',\n",
       " 'terms',\n",
       " 'people',\n",
       " 'cards',\n",
       " 'speedometer',\n",
       " 'numbers',\n",
       " 'cards',\n",
       " 'report',\n",
       " 'k',\n",
       " 'card',\n",
       " 'access',\n",
       " 'memory',\n",
       " 'card',\n",
       " 'cache',\n",
       " 'card',\n",
       " 'k',\n",
       " 'kind',\n",
       " 'numbers',\n",
       " 'cards',\n",
       " 'cache',\n",
       " 'cards',\n",
       " 'software',\n",
       " 'tech',\n",
       " 'notes',\n",
       " 'apple',\n",
       " 'com',\n",
       " 'cannon',\n",
       " 'camera',\n",
       " 'output',\n",
       " 'approx',\n",
       " 'pictures',\n",
       " 'disk',\n",
       " 'capability',\n",
       " 'sale',\n",
       " 'place',\n",
       " 'order',\n",
       " 'please',\n",
       " 'lgibb',\n",
       " 'nyx',\n",
       " 'cs',\n",
       " 'du',\n",
       " 'edu',\n",
       " 'color',\n",
       " 'table',\n",
       " 'problems',\n",
       " 'fast',\n",
       " 'quadra',\n",
       " 'card',\n",
       " 'use',\n",
       " 'course',\n",
       " 'matter',\n",
       " 'video',\n",
       " 'scroll',\n",
       " 'screen',\n",
       " 'color',\n",
       " 'vram',\n",
       " 'screen',\n",
       " 'bit',\n",
       " 'color',\n",
       " 'bit',\n",
       " 'cheers',\n",
       " 'tv',\n",
       " 'networks',\n",
       " 'see',\n",
       " 'speculation',\n",
       " 'behalf',\n",
       " 'world',\n",
       " 'way',\n",
       " 'years',\n",
       " 'way',\n",
       " 'soviets',\n",
       " 'victory',\n",
       " 'victim',\n",
       " 'complacency',\n",
       " 'program',\n",
       " 'efforts',\n",
       " 'fact',\n",
       " 'tradition',\n",
       " 'marvel',\n",
       " 'comics',\n",
       " 'destabilization',\n",
       " 'brezhnev',\n",
       " 'era',\n",
       " 'world',\n",
       " 'war',\n",
       " 'hmm',\n",
       " 'leap',\n",
       " 'numbers',\n",
       " 'refutation',\n",
       " 'someone',\n",
       " 'kind',\n",
       " 'email',\n",
       " 'relevant',\n",
       " 'information',\n",
       " 'letter',\n",
       " 'editor',\n",
       " 'copy',\n",
       " 'usn',\n",
       " 'wr',\n",
       " 'thanks',\n",
       " 'letter',\n",
       " 'use',\n",
       " 'info',\n",
       " 'folks',\n",
       " 'paper',\n",
       " 'post',\n",
       " 'paper',\n",
       " 'dan',\n",
       " 'dod',\n",
       " 'loki',\n",
       " 'acca',\n",
       " 'liberty',\n",
       " 'death',\n",
       " 'taylordf',\n",
       " 'colorado',\n",
       " 'edu',\n",
       " 'something',\n",
       " 'key',\n",
       " 'block',\n",
       " 'version',\n",
       " 'c',\n",
       " 'laureate',\n",
       " 'panacea',\n",
       " 'everything',\n",
       " 'cancer',\n",
       " 'wait',\n",
       " 'minute',\n",
       " 'k',\n",
       " 'compare',\n",
       " 'trends',\n",
       " 'gun',\n",
       " 'law',\n",
       " 'effect',\n",
       " 'handgun',\n",
       " 'pre',\n",
       " 'vs',\n",
       " 'post',\n",
       " 'comparison',\n",
       " 'utility',\n",
       " 'anything',\n",
       " 'correlation',\n",
       " 'correlation',\n",
       " 'causality',\n",
       " 'point',\n",
       " 'demographics',\n",
       " 'demographics',\n",
       " 'correlation',\n",
       " 'causality',\n",
       " 'vs',\n",
       " 'post',\n",
       " 'data',\n",
       " 'gun',\n",
       " 'law',\n",
       " 'effect',\n",
       " 'gun',\n",
       " 'gun',\n",
       " 'laws',\n",
       " 'hide',\n",
       " 'turn',\n",
       " 'gun',\n",
       " 'ownership',\n",
       " 'someone',\n",
       " 'street',\n",
       " 'problem',\n",
       " 'surveys',\n",
       " 'question',\n",
       " 'people',\n",
       " 'mean',\n",
       " 'vancouver',\n",
       " 'handguns',\n",
       " 'guns',\n",
       " 'beforehand',\n",
       " 'guns',\n",
       " 'purposes',\n",
       " 'defense',\n",
       " 'defense',\n",
       " 'points',\n",
       " 'differences',\n",
       " 'resort',\n",
       " 'kind',\n",
       " 'argument',\n",
       " 'movement',\n",
       " 'debate',\n",
       " 'produce',\n",
       " 'data',\n",
       " 'order',\n",
       " 'point',\n",
       " 'flaws',\n",
       " 'methodology',\n",
       " 'conclusions',\n",
       " 'study',\n",
       " 'resort',\n",
       " 'pc',\n",
       " 'tactics',\n",
       " 'mac',\n",
       " 'k',\n",
       " 'mac',\n",
       " 'problem',\n",
       " 'screens',\n",
       " 'jolt',\n",
       " 'drive',\n",
       " 'computer',\n",
       " 'wires',\n",
       " 'boards',\n",
       " 'board',\n",
       " 'jiggling',\n",
       " 'wires',\n",
       " 'blanking',\n",
       " 'anything',\n",
       " 'power',\n",
       " 'supply',\n",
       " 'crt',\n",
       " 'computer',\n",
       " 'thanks',\n",
       " 'advice',\n",
       " 'bodin',\n",
       " 'tufts',\n",
       " 'university',\n",
       " 'tufts',\n",
       " 'boxer',\n",
       " 'feinstein',\n",
       " 'trio',\n",
       " 'letter',\n",
       " 'batf',\n",
       " 'approach',\n",
       " 'style',\n",
       " 'assault',\n",
       " 'house',\n",
       " 'kids',\n",
       " 'letter',\n",
       " 'batf',\n",
       " 'text',\n",
       " 'reply',\n",
       " 'letter',\n",
       " 'section',\n",
       " 'letter',\n",
       " 'parts',\n",
       " 'logo',\n",
       " 'badges',\n",
       " 'loss',\n",
       " 'element',\n",
       " 'surprise',\n",
       " 'letter',\n",
       " 'richard',\n",
       " 'l',\n",
       " 'garner',\n",
       " 'operations',\n",
       " 'division',\n",
       " 'building',\n",
       " 'round',\n",
       " 'tail',\n",
       " 'light',\n",
       " 'bimmers',\n",
       " 'reganomics',\n",
       " 'quiche',\n",
       " 'yuppies',\n",
       " 'market',\n",
       " 'beamers',\n",
       " 'hood',\n",
       " 'ornaments',\n",
       " 'orion',\n",
       " 'way',\n",
       " 'fiction',\n",
       " 'thick',\n",
       " 'layer',\n",
       " 'reaction',\n",
       " 'mass',\n",
       " 'sort',\n",
       " 'bomb',\n",
       " 'bomb',\n",
       " 'reaction',\n",
       " 'mass',\n",
       " 'transfers',\n",
       " 'pusher',\n",
       " 'plate',\n",
       " 'greyhound',\n",
       " 'radar',\n",
       " 'collision',\n",
       " 'prevention',\n",
       " 'system',\n",
       " 'use',\n",
       " 'radar',\n",
       " 'monitor',\n",
       " 'vehicles',\n",
       " 'speeds',\n",
       " 'signals',\n",
       " 'driver',\n",
       " 'something',\n",
       " 'news',\n",
       " 'reports',\n",
       " 'months',\n",
       " 'time',\n",
       " 'possibility',\n",
       " 'system',\n",
       " 'mention',\n",
       " 'bumper',\n",
       " 'traffic',\n",
       " 'camaro',\n",
       " 'mph',\n",
       " 'ye',\n",
       " 'bridge',\n",
       " 'support',\n",
       " 'mph',\n",
       " 'curve',\n",
       " 'something',\n",
       " 'stages',\n",
       " 'warnings',\n",
       " 'lights',\n",
       " 'warnings',\n",
       " 'ie',\n",
       " 'james',\n",
       " 'run',\n",
       " 'disk',\n",
       " 'drive',\n",
       " 'quantum',\n",
       " 'message',\n",
       " 'error',\n",
       " 'thread',\n",
       " 'record',\n",
       " 'tarid',\n",
       " 'tarblock',\n",
       " 'disk',\n",
       " 'fix',\n",
       " 'problem',\n",
       " 'norton',\n",
       " 'utils',\n",
       " 'disk',\n",
       " 'editor',\n",
       " 'look',\n",
       " 'tarblock',\n",
       " 'something',\n",
       " 'question',\n",
       " 'error',\n",
       " 'course',\n",
       " 'sorry',\n",
       " 'perijoves',\n",
       " 'language',\n",
       " 'buyer',\n",
       " 'trust',\n",
       " 'princes',\n",
       " 'proverb',\n",
       " 'analog',\n",
       " 'governments',\n",
       " 'time',\n",
       " 'idea',\n",
       " 'citizens',\n",
       " 'rights',\n",
       " 'government',\n",
       " 'writings',\n",
       " 'founders',\n",
       " 'englishmen',\n",
       " 'rights',\n",
       " 'times',\n",
       " 'technology',\n",
       " 'changes',\n",
       " 'possibility',\n",
       " 'governments',\n",
       " 'mankind',\n",
       " 'system',\n",
       " 'people',\n",
       " 'anything',\n",
       " 'feudal',\n",
       " 'lords',\n",
       " 'slaveowners',\n",
       " 'freedom',\n",
       " 'speech',\n",
       " 'freedom',\n",
       " 'religion',\n",
       " 'attack',\n",
       " 'question',\n",
       " 'day',\n",
       " 'year',\n",
       " 'function',\n",
       " 'hours',\n",
       " 'equator',\n",
       " 'discrepancy',\n",
       " 'fact',\n",
       " 'difference',\n",
       " 'change',\n",
       " 'temperature',\n",
       " 'seasons',\n",
       " 'difference',\n",
       " 'daylight',\n",
       " 'hours',\n",
       " 'move',\n",
       " 'centaur',\n",
       " 'technology',\n",
       " 'state',\n",
       " 'someone',\n",
       " 'thiokol',\n",
       " 'manager',\n",
       " 'hat',\n",
       " 'customer',\n",
       " 'look',\n",
       " 'idea',\n",
       " 'r',\n",
       " 'tires',\n",
       " 'bird',\n",
       " 'car',\n",
       " 'anything',\n",
       " 'drove',\n",
       " 'miles',\n",
       " 'profile',\n",
       " 'corners',\n",
       " 'please',\n",
       " 'contact',\n",
       " 'dusmadso',\n",
       " 'idbsu',\n",
       " 'idbsu',\n",
       " 'idaho',\n",
       " 'usa',\n",
       " 'things',\n",
       " 'utility',\n",
       " 'company',\n",
       " 'buy',\n",
       " 'boiler',\n",
       " 'cleaning',\n",
       " 'system',\n",
       " 'operators',\n",
       " 'system',\n",
       " 'rumour',\n",
       " 'costs',\n",
       " 'unit',\n",
       " 'automation',\n",
       " 'scale',\n",
       " 'pixels',\n",
       " 'display',\n",
       " 'place',\n",
       " 'random',\n",
       " 'anybody',\n",
       " 'suggestions',\n",
       " 'mailings',\n",
       " 'thanks',\n",
       " 'press',\n",
       " 'release',\n",
       " 'house',\n",
       " 'president',\n",
       " 'clinton',\n",
       " 'remarks',\n",
       " 'desk',\n",
       " 'house',\n",
       " 'office',\n",
       " 'press',\n",
       " 'secretary',\n",
       " 'washington',\n",
       " 'newswire',\n",
       " 'remarks',\n",
       " 'president',\n",
       " 'question',\n",
       " 'answer',\n",
       " 'session',\n",
       " 'press',\n",
       " 'part',\n",
       " 'questions',\n",
       " 'ask',\n",
       " 'children',\n",
       " 'gas',\n",
       " 'masks',\n",
       " 'children',\n",
       " 'chance',\n",
       " 'gas',\n",
       " 'children',\n",
       " 'gas',\n",
       " 'masks',\n",
       " 'th',\n",
       " 'people',\n",
       " 'practice',\n",
       " 'religion',\n",
       " 'president',\n",
       " 'treasury',\n",
       " 'department',\n",
       " 'laws',\n",
       " 'number',\n",
       " 'laws',\n",
       " 'president',\n",
       " 'question',\n",
       " 'gas',\n",
       " 'masks',\n",
       " 'tell',\n",
       " 'purpose',\n",
       " 'gas',\n",
       " 'kill',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'anybody',\n",
       " 'things',\n",
       " 'heard',\n",
       " 'get',\n",
       " 'details',\n",
       " 'things',\n",
       " 'today',\n",
       " 'windows',\n",
       " 'gas',\n",
       " 'effect',\n",
       " 'compound',\n",
       " 'bus',\n",
       " 'children',\n",
       " 'children',\n",
       " 'humane',\n",
       " 'thing',\n",
       " 'children',\n",
       " 'someplace',\n",
       " 'terms',\n",
       " 'gas',\n",
       " 'masks',\n",
       " 'yesterday',\n",
       " 'fact',\n",
       " 'question',\n",
       " 'gas',\n",
       " 'compound',\n",
       " 'gas',\n",
       " 'masks',\n",
       " 'gas',\n",
       " 'masks',\n",
       " 'gas',\n",
       " 'circumstance',\n",
       " 'ms',\n",
       " 'myers',\n",
       " 'question',\n",
       " 'mr',\n",
       " 'president',\n",
       " 'q',\n",
       " 'janet',\n",
       " 'reno',\n",
       " 'possibility',\n",
       " 'mass',\n",
       " 'suicide',\n",
       " 'fire',\n",
       " 'explosion',\n",
       " 'moments',\n",
       " 'president',\n",
       " 'janet',\n",
       " 'reno',\n",
       " 'things',\n",
       " 'course',\n",
       " 'issue',\n",
       " 'people',\n",
       " 'kinds',\n",
       " 'issues',\n",
       " 'risk',\n",
       " 'tomorrow',\n",
       " 'day',\n",
       " 'day',\n",
       " 'judgment',\n",
       " 'course',\n",
       " 'fire',\n",
       " 'concern',\n",
       " 'children',\n",
       " 'burn',\n",
       " 'thing',\n",
       " 'thank',\n",
       " 'mr',\n",
       " 'president',\n",
       " 'janet',\n",
       " 'reno',\n",
       " 'decision',\n",
       " 'end',\n",
       " 'decision',\n",
       " 'president',\n",
       " 'hour',\n",
       " 'briefing',\n",
       " 'fbi',\n",
       " 'part',\n",
       " 'decision',\n",
       " 'responsibility',\n",
       " 'president',\n",
       " 'states',\n",
       " 'decision',\n",
       " 'authority',\n",
       " 'call',\n",
       " 'time',\n",
       " 'decision',\n",
       " 'change',\n",
       " 'mind',\n",
       " 'tomorrow',\n",
       " 'support',\n",
       " 'support',\n",
       " 'people',\n",
       " 'duties',\n",
       " 'fashion',\n",
       " 'situation',\n",
       " 'applause',\n",
       " 'mac',\n",
       " 'sound',\n",
       " 'hardware',\n",
       " 'diverse',\n",
       " 'macs',\n",
       " 'play',\n",
       " 'stereo',\n",
       " 'mix',\n",
       " 'output',\n",
       " 'instance',\n",
       " 'others',\n",
       " 'stereo',\n",
       " 'channel',\n",
       " 'speaker',\n",
       " 'lc',\n",
       " 'developers',\n",
       " 'stuff',\n",
       " 'channel',\n",
       " 'channel',\n",
       " 'data',\n",
       " 'data',\n",
       " 'channel',\n",
       " 'course',\n",
       " 'cheers',\n",
       " 'mail',\n",
       " 'address',\n",
       " 'corporation',\n",
       " 'address',\n",
       " 'corporation',\n",
       " 'cooper',\n",
       " 'court',\n",
       " 'califonia',\n",
       " 'access',\n",
       " 'please',\n",
       " 'mail',\n",
       " 'address',\n",
       " 'zia',\n",
       " 'ac',\n",
       " 'ed',\n",
       " 'castle',\n",
       " 'advance',\n",
       " 'toyota',\n",
       " 'market',\n",
       " 'wagons',\n",
       " 'sedan',\n",
       " 'something',\n",
       " 'camry',\n",
       " 'station',\n",
       " 'wagon',\n",
       " 'bears',\n",
       " 'resemblance',\n",
       " 'hearse',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst=[]\n",
    "for i in doc_df['Final']:\n",
    "    x = myfun(i)\n",
    "    lst.extend(x)\n",
    "lst   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram = CountVectorizer()\n",
    "unigram.fit(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<123458x17227 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 118448 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTM = unigram.fit_transform(lst)\n",
    "DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
      "                          evaluate_every=-1, learning_decay=0.7,\n",
      "                          learning_method='batch', learning_offset=10.0,\n",
      "                          max_doc_update_iter=100, max_iter=10,\n",
      "                          mean_change_tol=0.001, n_components=5, n_jobs=None,\n",
      "                          perp_tol=0.1, random_state=0, topic_word_prior=None,\n",
      "                          total_samples=1000000.0, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components= 5, max_iter=10,random_state =0 )\n",
    "lda_output = lda.fit_transform(DTM)\n",
    "print(lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Documnet  -topic matrix\n",
    "\n",
    "topic_name = ['Topic '+str(i) for i in range(lda.n_components)]\n",
    "doc_name = [ 'Document '+str(i) for i in range(DTM.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Document 0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document 1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document 2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document 3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document 4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Topic 0  Topic 1  Topic 2  Topic 3  Topic 4\n",
       "Document 0      0.1      0.1      0.6      0.1      0.1\n",
       "Document 1      0.1      0.1      0.6      0.1      0.1\n",
       "Document 2      0.1      0.6      0.1      0.1      0.1\n",
       "Document 3      0.1      0.1      0.1      0.1      0.6\n",
       "Document 4      0.1      0.6      0.1      0.1      0.1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_document_topic = pd.DataFrame(np.round(lda_output,2),columns=topic_name,index=doc_name)\n",
    "df_document_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaah</th>\n",
       "      <th>aacvkc</th>\n",
       "      <th>aad</th>\n",
       "      <th>aaef</th>\n",
       "      <th>aalm</th>\n",
       "      <th>aamir</th>\n",
       "      <th>aamrl</th>\n",
       "      <th>aan</th>\n",
       "      <th>...</th>\n",
       "      <th>zwrm</th>\n",
       "      <th>zx</th>\n",
       "      <th>zxf</th>\n",
       "      <th>zxm</th>\n",
       "      <th>zxqi</th>\n",
       "      <th>zy</th>\n",
       "      <th>zyg</th>\n",
       "      <th>zyhszg</th>\n",
       "      <th>zyxel</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>0.200034</td>\n",
       "      <td>0.200039</td>\n",
       "      <td>1.199815</td>\n",
       "      <td>0.200045</td>\n",
       "      <td>0.200044</td>\n",
       "      <td>0.200044</td>\n",
       "      <td>0.200044</td>\n",
       "      <td>0.200035</td>\n",
       "      <td>0.200038</td>\n",
       "      <td>0.200035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200047</td>\n",
       "      <td>7.199856</td>\n",
       "      <td>0.200045</td>\n",
       "      <td>0.200045</td>\n",
       "      <td>0.200047</td>\n",
       "      <td>0.200038</td>\n",
       "      <td>0.200044</td>\n",
       "      <td>0.200044</td>\n",
       "      <td>0.200038</td>\n",
       "      <td>3.199847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>7.199862</td>\n",
       "      <td>0.200040</td>\n",
       "      <td>0.200047</td>\n",
       "      <td>0.200046</td>\n",
       "      <td>1.199823</td>\n",
       "      <td>0.200045</td>\n",
       "      <td>1.199823</td>\n",
       "      <td>0.200037</td>\n",
       "      <td>2.199846</td>\n",
       "      <td>0.200037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200049</td>\n",
       "      <td>0.200037</td>\n",
       "      <td>0.200046</td>\n",
       "      <td>0.200046</td>\n",
       "      <td>0.200049</td>\n",
       "      <td>2.199846</td>\n",
       "      <td>0.200045</td>\n",
       "      <td>1.199823</td>\n",
       "      <td>0.200039</td>\n",
       "      <td>0.200039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>0.200033</td>\n",
       "      <td>0.200037</td>\n",
       "      <td>0.200044</td>\n",
       "      <td>0.200043</td>\n",
       "      <td>0.200043</td>\n",
       "      <td>0.200043</td>\n",
       "      <td>0.200043</td>\n",
       "      <td>0.200034</td>\n",
       "      <td>0.200037</td>\n",
       "      <td>0.200034</td>\n",
       "      <td>...</td>\n",
       "      <td>1.199808</td>\n",
       "      <td>0.200034</td>\n",
       "      <td>0.200043</td>\n",
       "      <td>0.200043</td>\n",
       "      <td>1.199808</td>\n",
       "      <td>0.200037</td>\n",
       "      <td>0.200043</td>\n",
       "      <td>0.200043</td>\n",
       "      <td>0.200037</td>\n",
       "      <td>0.200036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>0.200035</td>\n",
       "      <td>2.199844</td>\n",
       "      <td>0.200047</td>\n",
       "      <td>1.199820</td>\n",
       "      <td>0.200045</td>\n",
       "      <td>0.200045</td>\n",
       "      <td>0.200045</td>\n",
       "      <td>0.200036</td>\n",
       "      <td>0.200039</td>\n",
       "      <td>0.200036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200048</td>\n",
       "      <td>0.200036</td>\n",
       "      <td>1.199820</td>\n",
       "      <td>1.199820</td>\n",
       "      <td>0.200048</td>\n",
       "      <td>0.200039</td>\n",
       "      <td>0.200045</td>\n",
       "      <td>0.200045</td>\n",
       "      <td>0.200039</td>\n",
       "      <td>0.200038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 4</th>\n",
       "      <td>0.200036</td>\n",
       "      <td>0.200040</td>\n",
       "      <td>0.200047</td>\n",
       "      <td>0.200046</td>\n",
       "      <td>0.200046</td>\n",
       "      <td>1.199823</td>\n",
       "      <td>0.200046</td>\n",
       "      <td>4.199858</td>\n",
       "      <td>0.200040</td>\n",
       "      <td>4.199858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200049</td>\n",
       "      <td>0.200037</td>\n",
       "      <td>0.200046</td>\n",
       "      <td>0.200046</td>\n",
       "      <td>0.200049</td>\n",
       "      <td>0.200040</td>\n",
       "      <td>1.199823</td>\n",
       "      <td>0.200046</td>\n",
       "      <td>2.199847</td>\n",
       "      <td>0.200039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 17227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               aa       aaa      aaah    aacvkc       aad      aaef      aalm  \\\n",
       "Topic 0  0.200034  0.200039  1.199815  0.200045  0.200044  0.200044  0.200044   \n",
       "Topic 1  7.199862  0.200040  0.200047  0.200046  1.199823  0.200045  1.199823   \n",
       "Topic 2  0.200033  0.200037  0.200044  0.200043  0.200043  0.200043  0.200043   \n",
       "Topic 3  0.200035  2.199844  0.200047  1.199820  0.200045  0.200045  0.200045   \n",
       "Topic 4  0.200036  0.200040  0.200047  0.200046  0.200046  1.199823  0.200046   \n",
       "\n",
       "            aamir     aamrl       aan  ...      zwrm        zx       zxf  \\\n",
       "Topic 0  0.200035  0.200038  0.200035  ...  0.200047  7.199856  0.200045   \n",
       "Topic 1  0.200037  2.199846  0.200037  ...  0.200049  0.200037  0.200046   \n",
       "Topic 2  0.200034  0.200037  0.200034  ...  1.199808  0.200034  0.200043   \n",
       "Topic 3  0.200036  0.200039  0.200036  ...  0.200048  0.200036  1.199820   \n",
       "Topic 4  4.199858  0.200040  4.199858  ...  0.200049  0.200037  0.200046   \n",
       "\n",
       "              zxm      zxqi        zy       zyg    zyhszg     zyxel        zz  \n",
       "Topic 0  0.200045  0.200047  0.200038  0.200044  0.200044  0.200038  3.199847  \n",
       "Topic 1  0.200046  0.200049  2.199846  0.200045  1.199823  0.200039  0.200039  \n",
       "Topic 2  0.200043  1.199808  0.200037  0.200043  0.200043  0.200037  0.200036  \n",
       "Topic 3  1.199820  0.200048  0.200039  0.200045  0.200045  0.200039  0.200038  \n",
       "Topic 4  0.200046  0.200049  0.200040  1.199823  0.200046  2.199847  0.200039  \n",
       "\n",
       "[5 rows x 17227 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the data frame between topic and terms\n",
    "\n",
    "df_topic_keywords = pd.DataFrame(lda.components_,)\n",
    "\n",
    "\n",
    "#Naming the columns and rows \n",
    "\n",
    "df_topic_keywords.columns= unigram.get_feature_names()\n",
    "df_topic_keywords.index = topic_name\n",
    "df_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the top 20 words for each topic\n",
    "\n",
    "def show_topic(unigram, lda, n_words):\n",
    "    keywords = np.array(unigram.get_feature_names())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in lda.components_:\n",
    "        topic_keywords_loc = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(topic_keywords_loc))\n",
    "    return topic_keywords\n",
    "topic_keywords = show_topic(unigram= unigram , lda =lda ,n_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['power', 'price', 'things', 'law', 'state', 'work', 'firearms',\n",
       "        'day', 'get', 'world', 'list', 'speed', 'problems', 'model', 'lot',\n",
       "        'earth', 'fact', 'defense', 'auto', 'moon'], dtype='<U33'),\n",
       " array(['time', 'use', 'way', 'apple', 'case', 'mac', 'weapons', 'card',\n",
       "        'cd', 'monitor', 'place', 'line', 'mission', 'rate', 'station',\n",
       "        'center', 'idea', 'questions', 'flight', 'issue'], dtype='<U33'),\n",
       " array(['space', 'system', 'gun', 'year', 'problem', 'anyone', 'data',\n",
       "        'edu', 'something', 'information', 'government', 'number',\n",
       "        'please', 'thing', 'cars', 'bit', 'anything', 'money', 'disk',\n",
       "        'condition'], dtype='<U33'),\n",
       " array(['people', 'thanks', 'control', 'sale', 'mail', 'software', 'com',\n",
       "        'someone', 'program', 'file', 'part', 'cost', 'order', 'course',\n",
       "        'times', 'news', 'mb', 'article', 'systems', 'support'],\n",
       "       dtype='<U33'),\n",
       " array(['car', 'drive', 'years', 'point', 'guns', 'offer', 'computer',\n",
       "        'memory', 'launch', 'engine', 'bill', 'orbit', 'technology',\n",
       "        'research', 'others', 'dos', 'vehicle', 'life', 'hardware', 'box'],\n",
       "       dtype='<U33')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>power</td>\n",
       "      <td>price</td>\n",
       "      <td>things</td>\n",
       "      <td>law</td>\n",
       "      <td>state</td>\n",
       "      <td>work</td>\n",
       "      <td>firearms</td>\n",
       "      <td>day</td>\n",
       "      <td>get</td>\n",
       "      <td>world</td>\n",
       "      <td>list</td>\n",
       "      <td>speed</td>\n",
       "      <td>problems</td>\n",
       "      <td>model</td>\n",
       "      <td>lot</td>\n",
       "      <td>earth</td>\n",
       "      <td>fact</td>\n",
       "      <td>defense</td>\n",
       "      <td>auto</td>\n",
       "      <td>moon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>time</td>\n",
       "      <td>use</td>\n",
       "      <td>way</td>\n",
       "      <td>apple</td>\n",
       "      <td>case</td>\n",
       "      <td>mac</td>\n",
       "      <td>weapons</td>\n",
       "      <td>card</td>\n",
       "      <td>cd</td>\n",
       "      <td>monitor</td>\n",
       "      <td>place</td>\n",
       "      <td>line</td>\n",
       "      <td>mission</td>\n",
       "      <td>rate</td>\n",
       "      <td>station</td>\n",
       "      <td>center</td>\n",
       "      <td>idea</td>\n",
       "      <td>questions</td>\n",
       "      <td>flight</td>\n",
       "      <td>issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>space</td>\n",
       "      <td>system</td>\n",
       "      <td>gun</td>\n",
       "      <td>year</td>\n",
       "      <td>problem</td>\n",
       "      <td>anyone</td>\n",
       "      <td>data</td>\n",
       "      <td>edu</td>\n",
       "      <td>something</td>\n",
       "      <td>information</td>\n",
       "      <td>government</td>\n",
       "      <td>number</td>\n",
       "      <td>please</td>\n",
       "      <td>thing</td>\n",
       "      <td>cars</td>\n",
       "      <td>bit</td>\n",
       "      <td>anything</td>\n",
       "      <td>money</td>\n",
       "      <td>disk</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>people</td>\n",
       "      <td>thanks</td>\n",
       "      <td>control</td>\n",
       "      <td>sale</td>\n",
       "      <td>mail</td>\n",
       "      <td>software</td>\n",
       "      <td>com</td>\n",
       "      <td>someone</td>\n",
       "      <td>program</td>\n",
       "      <td>file</td>\n",
       "      <td>part</td>\n",
       "      <td>cost</td>\n",
       "      <td>order</td>\n",
       "      <td>course</td>\n",
       "      <td>times</td>\n",
       "      <td>news</td>\n",
       "      <td>mb</td>\n",
       "      <td>article</td>\n",
       "      <td>systems</td>\n",
       "      <td>support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 4</th>\n",
       "      <td>car</td>\n",
       "      <td>drive</td>\n",
       "      <td>years</td>\n",
       "      <td>point</td>\n",
       "      <td>guns</td>\n",
       "      <td>offer</td>\n",
       "      <td>computer</td>\n",
       "      <td>memory</td>\n",
       "      <td>launch</td>\n",
       "      <td>engine</td>\n",
       "      <td>bill</td>\n",
       "      <td>orbit</td>\n",
       "      <td>technology</td>\n",
       "      <td>research</td>\n",
       "      <td>others</td>\n",
       "      <td>dos</td>\n",
       "      <td>vehicle</td>\n",
       "      <td>life</td>\n",
       "      <td>hardware</td>\n",
       "      <td>box</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             1       2        3      4        5         6         7        8   \\\n",
       "Topic 0   power   price   things    law    state      work  firearms      day   \n",
       "Topic 1    time     use      way  apple     case       mac   weapons     card   \n",
       "Topic 2   space  system      gun   year  problem    anyone      data      edu   \n",
       "Topic 3  people  thanks  control   sale     mail  software       com  someone   \n",
       "Topic 4     car   drive    years  point     guns     offer  computer   memory   \n",
       "\n",
       "                9            10          11      12          13        14  \\\n",
       "Topic 0        get        world        list   speed    problems     model   \n",
       "Topic 1         cd      monitor       place    line     mission      rate   \n",
       "Topic 2  something  information  government  number      please     thing   \n",
       "Topic 3    program         file        part    cost       order    course   \n",
       "Topic 4     launch       engine        bill   orbit  technology  research   \n",
       "\n",
       "              15      16        17         18        19         20  \n",
       "Topic 0      lot   earth      fact    defense      auto       moon  \n",
       "Topic 1  station  center      idea  questions    flight      issue  \n",
       "Topic 2     cars     bit  anything      money      disk  condition  \n",
       "Topic 3    times    news        mb    article   systems    support  \n",
       "Topic 4   others     dos   vehicle       life  hardware        box  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_20 = pd.DataFrame(topic_keywords,index=topic_name,columns=np.arange(1,21))#columns=topic_name,\n",
    "Top_20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=LatentDirichletAllocation(batch_size=128,\n",
       "                                                 doc_topic_prior=None,\n",
       "                                                 evaluate_every=-1,\n",
       "                                                 learning_decay=0.7,\n",
       "                                                 learning_method='batch',\n",
       "                                                 learning_offset=10.0,\n",
       "                                                 max_doc_update_iter=100,\n",
       "                                                 max_iter=10,\n",
       "                                                 mean_change_tol=0.001,\n",
       "                                                 n_components=10, n_jobs=None,\n",
       "                                                 perp_tol=0.1,\n",
       "                                                 random_state=None,\n",
       "                                                 topic_word_prior=None,\n",
       "                                                 total_samples=1000000.0,\n",
       "                                                 verbose=0),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'n_components': [2, 3, 4, 5, 6, 7, 8, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "search_params = {'n_components':[2,3,4,5,6,7,8,10]}\n",
    "\n",
    "lda = LatentDirichletAllocation()\n",
    "\n",
    "model = GridSearchCV(lda,param_grid=search_params)\n",
    "\n",
    "model.fit(DTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lda_model = model.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
